name: Comprehensive Test Suite

on:
  push:
    branches: [ main, develop, claude/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual trigger

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Cache system dependencies
      uses: actions/cache@v3
      id: apt-cache
      with:
        path: /var/cache/apt
        key: ${{ runner.os }}-apt-pygame-${{ hashFiles('.github/workflows/comprehensive-tests.yml') }}
        restore-keys: |
          ${{ runner.os }}-apt-pygame-

    - name: Install system dependencies for pygame
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-dev libsdl2-dev libsdl2-image-dev libsdl2-mixer-dev libsdl2-ttf-dev libfreetype6-dev libportmidi-dev

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Check code formatting with black
      run: |
        black --check . --exclude='\.git|__pycache__|\.pytest_cache'
      continue-on-error: true

    - name: Check import sorting with isort
      run: |
        isort --check-only . --skip .git --skip __pycache__ --skip .pytest_cache --profile black
      continue-on-error: true

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics --exclude=.git,__pycache__,.pytest_cache
      continue-on-error: false

    - name: Run unit tests with coverage
      run: |
        pytest tests/ -v -m "not integration and not performance and not stress" \
          --cov=. --cov-report=xml --cov-report=term-missing --cov-branch \
          --maxfail=5

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml
        flags: unittests
        name: codecov-unit-tests
        fail_ci_if_error: false
      continue-on-error: true

    - name: Archive test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: unit-test-results
        path: |
          coverage.xml
          htmlcov/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests  # Run after unit tests pass

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-dev libsdl2-dev libsdl2-image-dev libsdl2-mixer-dev libsdl2-ttf-dev libfreetype6-dev libportmidi-dev

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run integration tests
      run: |
        pytest tests/ -v -m integration --tb=short --maxfail=3

    - name: Archive integration test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-results
        path: .pytest_cache/

  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: unit-tests  # Run after unit tests pass

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-dev libsdl2-dev libsdl2-image-dev libsdl2-mixer-dev libsdl2-ttf-dev libfreetype6-dev libportmidi-dev

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run performance benchmarks
      run: |
        pytest tests/ -v -m performance --tb=short -s

    - name: Archive performance results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: performance-results
        path: .pytest_cache/

  stress-tests:
    name: Stress Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]  # Run after unit and integration tests pass
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    # Only run stress tests on main/develop pushes to save CI time

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-dev libsdl2-dev libsdl2-image-dev libsdl2-mixer-dev libsdl2-ttf-dev libfreetype6-dev libportmidi-dev

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run stress tests
      run: |
        pytest tests/ -v -m stress --tb=short -s
      timeout-minutes: 30  # Stress tests can take a while

    - name: Archive stress test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: stress-test-results
        path: .pytest_cache/

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests]
    if: always()

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4

    - name: Display test summary
      run: |
        echo "================================"
        echo "COMPREHENSIVE TEST SUITE SUMMARY"
        echo "================================"
        echo ""
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Performance Tests: ${{ needs.performance-tests.result }}"
        if [ "${{ needs.stress-tests.result }}" != "" ]; then
          echo "Stress Tests: ${{ needs.stress-tests.result }}"
        else
          echo "Stress Tests: Skipped (only run on main/develop)"
        fi
        echo ""
        echo "================================"

    - name: Check if tests passed
      if: |
        needs.unit-tests.result != 'success' ||
        needs.integration-tests.result != 'success' ||
        needs.performance-tests.result != 'success'
      run: |
        echo "Some tests failed!"
        exit 1
